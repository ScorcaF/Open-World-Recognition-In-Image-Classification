{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataClean.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"7xhrRvbYiuo6"},"source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from torchvision import datasets\n","from PIL import Image\n","\n","\n","class Cifar100(torch.utils.data.Dataset):             \n","    \n","    def __init__(self, root, train, download, random_state, transform=None):\n","        self.train = train                            #Boolean: state if we want or not the trainset\n","        self.transform = transform                    #set of transformation to apply to our dataset (ToTensor(), Normalize(), standardization etc.)\n","        self.is_transform_enabled = True              \n","        \n","        self.dataset = datasets.cifar.CIFAR100(       #cifar100 dataset\n","            root=root,\n","            train=train,\n","            download=download,\n","            transform=None)\n","\n","        self.targets = np.array(self.dataset.targets)  # we extract the target label from the dataset\n","\n","        # Use make_split(k:[batch labels]) to build k-th split dataset: this method is defined below, in the class.\n","        self.batch_splits = self.make_split(random_state)\n","\n","    def make_split(self, random_state):  #--> make_split()\n","            #random shuffle \n","            #of a vector containing class label (0-99):\n","            np.random.seed(random_state)                   # Useful to reproduce same values every time\n","            random_labels = list(range(0, 100))            # [0-99] labels\n","            np.random.shuffle(random_labels)               # shuffle of the index\n","\n","            ten_split = np.array_split(random_labels, 10)  # we split our shuffled array in 10 sized chunks\n","           \n","            batch_splits = dict.fromkeys(np.arange(0, 10)) #initialize the dict for splits\n","            for i in range(10):\n","              batch_splits[i]=ten_split[i].tolist()        # {0:[1-st chunk], 1:[...], ... , 9:[...]} \n","\n","            # save label mapping\n","            #we save the label mapping generated by the shuffle\n","            #example: {0:72, 1:67 ... 99:32} <-- generated by the shuffle\n","            self.label_map = {k:v for v,k in enumerate(random_labels)}    \n","           \n","            return batch_splits                            \n","\n","        \n","    def set_classes_batch(self, batch_idx): \n","        \"\"\" Args:\n","            batch_idx: array of ten element, 10 classes of the current split \n","                (e.g. self.batch_splits[0])\n","        \"\"\"\n","\n","        self.batch_idx  =  batch_idx                \n","\n","        # retrieve element of the classes of the current split\n","        # Boolean mask returning only indexes where targets match an element of batch_idx \n","        mask = np.isin(self.targets, self.batch_idx)      # True if target is in batch_idx\n","                                                          \n","\n","        # Batch indices of interest\n","        idxes = np.where(mask)[0]     \n","        self.idxes = np.array(idxes)  \n","\n","             \n","        #we save in self.batches_mapping a dictionary like this:\n","        ##              {0:37 ,1:34, ... , 999:2}\n","        #key are value from 0-999, values are index that refers to item belonging to the 10 classes in our split\n","\n","        # this will be used in __getitem__ : __getitem__ generates random number from [0 - __len__];\n","        # we need to translate those numbers in indexes corresponding to data belonging to our split\n","       \n","        self.batches_mapping = {fake_idxes : real_idxes    for fake_idxes, real_idxes in enumerate(idxes)}\n","\n","        # fake_idxes = [0-999] index used in __getitem__ to retrieve record of interest\n","        # real_idxes = [index data of our current splits] index used in __getitem__ to return element form self.dataset\n","\n","\n","    def __len__(self):\n","        return len(self.batches_mapping)         # we set the max value of idx in the __getitem__ method\n","\n","\n","    def __getitem__(self, fake_idxes):       \n","       \n","        real_idxes = self.batches_mapping[fake_idxes]    \n","        image = self.dataset.data[real_idxes]            # imageS of selected chunk\n","        label = self.dataset.targets[real_idxes]         # labelS of selected chunk\n","\n","        image = Image.fromarray(image)           # Return a PIL image (an Image object)\n","\n","        # Applies preprocessing when accessing the image if transformations are currently enabled\n","        if (self.transform is not None) and (self.is_transform_enabled is True):\n","            image = self.transform(image)\n","\n","        mapped_label = self.label_map[label]     \n","      \n","        return image,mapped_label\n","\n","    def enable_transform(self):\n","        self.is_transform_enabled = True\n","\n","    def disable_transform(self):\n","        self.is_transform_enabled = False\n","\n","    def transform_status(self):\n","        return self.is_transform_enabled"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtHyEKydb9nO"},"source":[""],"execution_count":null,"outputs":[]}]}
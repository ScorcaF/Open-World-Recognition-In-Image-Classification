{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"owr_main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jLZPlWlek2XI"},"source":["# import libraries and package\n"]},{"cell_type":"code","metadata":{"id":"wkBUBd8bQ6HE"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","from torch.utils.data import Dataset, Subset, DataLoader, ConcatDataset\n","\n","from torchvision import transforms\n","from torchvision.models import resnet34\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","from PIL import Image\n","from copy import deepcopy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E_OSaUaoksjR"},"source":["righe di codice utili per importare da altri jupyter notebook delle funzioni. "]},{"cell_type":"code","metadata":{"id":"i2MXsnVKxbzx"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TrWrAj7bjtv5"},"source":["%cd \"/content/drive/MyDrive/MLDL2021_Calderaro_Giannuzzi_Scorca/File colab/File progetto\"\n","!pip install import-ipynb\n","\n","import import_ipynb                           "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKzmzOrAkGiM"},"source":["#retrieve from folder 'data'\n","%cd \"/content/drive/MyDrive/MLDL2021_Calderaro_Giannuzzi_Scorca/File colab/File progetto/data\"                          \n","from DataClean import Cifar100 as datasetManager   \n","\n","#retrieve from folder 'models'\n","%cd \"/content/drive/MyDrive/MLDL2021_Calderaro_Giannuzzi_Scorca/File colab/File progetto/models\"\n","from resnet import resnet32\n","from Manager import Manager\n","\n","#retrieve from folder 'extension'\n","%cd \"/content/drive/MyDrive/MLDL2021_Calderaro_Giannuzzi_Scorca/File colab/File progetto/owr\"\n","from iCarlwithRejectFC import iCaRLWithRejectFC\n","\n","#retrieve from folder 'logs'\n","%cd \"/content/drive/MyDrive/MLDL2021_Calderaro_Giannuzzi_Scorca/File colab/File progetto/logs\"\n","from Save_logs import save_logs\n","\n","# return in the main project folder\n","%cd \"/content/drive/MyDrive/MLDL2021_Calderaro_Giannuzzi_Scorca/File colab/File progetto\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zVIwT_NfRboW"},"source":["# Arguments"]},{"cell_type":"code","metadata":{"id":"vl63oUufRbJN"},"source":["DEVICE=torch.device(\"cuda:0\")\n","DIR='/content/data'\n","\n","RANDOM_SEED = [1993, 30, 423]     # choose and put here one seed for each different run\n","\n","NUM_CLASSES = 100       # Total number of classes\n","\n","# Training\n","BATCH_SIZE = 64         # Batch size \n","NUM_EPOCHS = 70         # Total number of training epochs\n","LR = 2                  # Initial learning rate\n","MOMENTUM = 0.9          # Momentum for stochastic gradient descent (SGD)\n","WEIGHT_DECAY = 1e-5     # Weight decay from iCaRL\n","MILESTONES = [49, 63]   # Step down policy from iCaRL (MultiStepLR)\n","                        # Decrease the learning rate by gamma at each milestone\n","GAMMA = 0.2             # Gamma factor from iCaRL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yD6XReTJSCX2"},"source":["train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n","                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","\n","test_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eh6UwxoOfqr4"},"source":["\n","# Closed World With Rejeciton and Open World With Rejection\n"]},{"cell_type":"code","metadata":{"id":"k7sG9LVnUg7H"},"source":["from iCarlwithRejectFC import iCaRLWithRejectFC\n","\n","logs_iCaRLwithReject = [[] for _ in range(len(RANDOM_SEED))]\n","\n","CUDA_LAUNCH_BLOCKING=1\n","NUM_RUNS = len(RANDOM_SEED)\n","NUM_EPOCHS = 70\n","\n","threshold = 0.80\n","RUN_NAME_CLOSED = 'icarl_rejectFC_newClosed_threshold80'\n","RUN_NAME_OPEN = 'icarl_rejectFC_newOpen_threshold80'\n","\n","\n","\n","# Initialize logs\n","logs_iCaRLwithReject_closed = [[] for _ in range(NUM_RUNS)]\n","logs_iCaRLwithReject_open = [[] for _ in range(NUM_RUNS)]\n","\n","\n","for run_i in range(NUM_RUNS):\n","\n","  train_dataset = datasetManager(DIR, train=True, download=True, random_state=RANDOM_SEED[run_i], transform=train_transform)\n","  test_dataset_open = datasetManager(DIR, train=False, download=False, random_state=RANDOM_SEED[run_i], transform=test_transform)\n","  test_dataset_closed = datasetManager(DIR, train=False, download=False, random_state=RANDOM_SEED[run_i], transform=test_transform)\n","\n","\n","    \n","  net = resnet32()\n","  icarl = iCaRLWithRejectFC(DEVICE, net, LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, NUM_EPOCHS, BATCH_SIZE, train_transform, test_transform)\n","\n","  test_dataset_open.set_classes_batch([test_dataset_open.batch_splits[i] for i in range(5, 10)])\n","\n","\n","  for split_i in range(5):\n","        print(f\"## Split {split_i} of run {run_i} ##\")\n","\n","\n","        train_dataset.set_classes_batch(train_dataset.batch_splits[split_i])\n","        test_dataset_closed.set_classes_batch([test_dataset_closed.batch_splits[i] for i in range(0, split_i+1)])\n","        \n","\n","        train_idx, val_idx = train_test_split(list(range(len(train_dataset))),      \n","                                          random_state=RANDOM_SEED[run_i],\n","                                          test_size = 0.1)   \n","                                          \n","        train_data_split = Subset(train_dataset , train_idx)                       \n","        val_data_split = Subset(train_dataset , val_idx)                           \n","        \n","        train_logs = icarl.incremental_train(split_i, train_data_split, val_data_split)\n","        \n","\n","\n","            #closed world\n","        logs_iCaRLwithReject_closed[run_i].append({})\n","\n","        acc, unk, all_targets, all_preds = icarl.test_without_classifier(test_dataset_closed, threshold)\n","\n","        logs_iCaRLwithReject_closed[run_i][split_i]['accuracy'] = acc\n","        logs_iCaRLwithReject_closed[run_i][split_i]['unknown'] = unk\n","        logs_iCaRLwithReject_closed[run_i][split_i]['conf_mat'] = confusion_matrix(all_targets.to('cpu'), all_preds.to('cpu'))\n","\n","    \n","\n","\n","            #open world\n","        logs_iCaRLwithReject_open[run_i].append({})\n","\n","        acc, unk, all_targets, all_preds = icarl.test_without_classifier(test_dataset_open, threshold)\n","\n","        logs_iCaRLwithReject_open[run_i][split_i]['accuracy'] = acc\n","        logs_iCaRLwithReject_open[run_i][split_i]['unknown'] = unk\n","        logs_iCaRLwithReject_open[run_i][split_i]['conf_mat'] = confusion_matrix(all_targets.to('cpu'), all_preds.to('cpu'))\n","\n","          \n","\n","save_logs(logs_iCaRLwithReject_closed,RANDOM_SEED, NUM_EPOCHS, RUN_NAME_CLOSED, BATCH_SIZE)\n","save_logs(logs_iCaRLwithReject_open,RANDOM_SEED, NUM_EPOCHS, RUN_NAME_OPEN, BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzpN8mnc7qT1"},"source":[""],"execution_count":null,"outputs":[]}]}
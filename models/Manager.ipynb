{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Manager.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"KM9idQVbL1Tn"},"source":["import torch\n","import torch.nn as nn\n","from torch.backends import cudnn\n","from copy import deepcopy\n","\n","class Manager():\n","\n","    def __init__(self, device, net, criterion, optimizer, scheduler, train_dataloader, val_dataloader, test_dataloader):\n","        self.device = device\n","\n","        self.net = net\n","        self.best_net = self.net       \n","\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","\n","        self.train_dataloader = train_dataloader\n","        self.val_dataloader = val_dataloader\n","        self.test_dataloader = test_dataloader\n","\n","\n","    def increment_classes(self, n=10): \n","        \n","        in_features = self.net.fc.in_features    # size of each input sample         \n","        out_features = self.net.fc.out_features  # size of each output sample\n","        weight = self.net.fc.weight.data\n","\n","        self.net.fc = nn.Linear(in_features, out_features+n)   #increment output neurons\n","        self.net.fc.weight.data[:out_features] = weight       \n","\n","\n","    def to_onehot(self, targets):\n","\n","\n","      num_classes = self.net.fc.out_features\n","      one_hot_targets = torch.eye(num_classes)[targets] \n","\n","      return one_hot_targets.to(self.device)\n","\n","    \n","    def train(self, num_epochs):\n","\n","\n","        self.net.to(self.device)\n","        cudnn.benchmark  # Calling this optimizes runtime \n","\n","        self.best_accuracy = 0 \n","        self.best_epoch = 0\n","\n","        for epoch in range(num_epochs):\n","            # Run an epoch (start counting form 1: so we add +1)\n","            train_loss, train_accuracy = self.do_epoch(epoch+1)  \n","        \n","            # Validate after each epoch \n","            val_loss, val_accuracy = self.validate()    \n","\n","            # Best validation model\n","            if val_accuracy > self.best_accuracy:     # we deepcopy the network if validation scores\n","                self.best_accuracy = val_accuracy     # are the best until now\n","                self.best_net = deepcopy(self.net)\n","                self.best_epoch = epoch\n","                \n","\n","            \n","\n","        return (train_loss, train_accuracy,\n","                val_loss, val_accuracy)\n","    \n","    def do_epoch(self, current_epoch):\n","\n","\n","        self.net.train()  #Set network in training mode \n","\n","        running_train_loss = 0\n","        running_corrects = 0\n","        total = 0\n","        batch_idx = 0\n","\n","        print(f\"Epoch: {current_epoch}, LR: {self.scheduler.get_last_lr()}\")   \n","\n","        for images, labels in self.train_dataloader:    \n","            loss, corrects = self.do_batch(images, labels)  #'do_batch' trains model for one batch\n","            running_train_loss += loss.item()\n","            running_corrects += corrects  \n","            total += labels.size(0)       \n","            batch_idx += 1                \n","\n","        self.scheduler.step()      #If you don’t call it, the learning rate won’t be changed over epochs and stays at the initial value.\n","\n","\n","        # Calculate average scores\n","        train_loss = running_train_loss / batch_idx       # Average loss over all batches seen in the epoch\n","        train_accuracy = running_corrects / float(total)  # Average accuracy over all samples (images) seen in the epoch\n","\n","        print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n","\n","        return (train_loss, train_accuracy)\n","\n","    def do_batch(self, batch, labels):  \n","\n","\n","        batch = batch.to(self.device)           #send to GPU label and batch\n","        labels = labels.to(self.device)\n","\n","        # Zero-ing the gradients\n","        self.optimizer.zero_grad()    #Sets gradients of all model parameters to zero before backpropragation\n","\n","        # One hot encoding of new task labels \n","        one_hot_labels = self.to_onehot(labels) # Size = [64, 10*iteration]  \n","\n","        # net forward pass\n","        outputs = self.net(batch)       \n","        \n","        loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs \n","                                                       \n","\n","        # Get predictions\n","        _, preds = torch.max(outputs.data, 1) \n","\n","        # Compute the number of correctly classified images\n","        running_corrects = \\\n","            torch.sum(preds == labels.data).data.item()  \n","\n","        # Backward pass: computes gradients\n","        loss.backward()  \n","\n","        # Update weights based on accumulated gradients\n","        self.optimizer.step()\n","\n","        return (loss, running_corrects)\n","\n","    def validate(self):    \n","\n","        self.net.train(False)   \n","\n","        running_val_loss = 0\n","        running_corrects = 0\n","        total = 0\n","        batch_idx = 0\n","\n","        for images, labels in self.val_dataloader:    \n","            images = images.to(self.device)           \n","            labels = labels.to(self.device)\n","            total += labels.size(0)\n","\n","            # One hot encoding of new task labels \n","            one_hot_labels = self.to_onehot(labels) # Size = [batch_size, 10*iteration]\n","\n","            # New net forward pass\n","            outputs = self.net(images)  \n","            loss = self.criterion(outputs, one_hot_labels) # BCE Loss with sigmoids over outputs\n","\n","            running_val_loss += loss.item()\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            running_corrects += torch.sum(preds == labels.data).data.item() # Update the number of correctly classified validation samples\n","\n","\n","            batch_idx += 1\n","\n","        \n","        val_loss = running_val_loss / batch_idx\n","        val_accuracy = running_corrects / float(total)\n","\n","        print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n","\n","        return (val_loss, val_accuracy)\n","\n","    def test(self):\n","\n","        self.best_net.train(False)  # Set Network to evaluation mode\n","                                    # we take the best net encountered during ephocs\n","        running_corrects = 0\n","        total = 0\n","\n","        all_preds = torch.tensor([]) # to store all predictions\n","        all_preds = all_preds.type(torch.LongTensor)\n","        all_targets = torch.tensor([])\n","        all_targets = all_targets.type(torch.LongTensor)\n","        \n","        for images, labels in self.test_dataloader:   \n","            images = images.to(self.device)\n","            labels = labels.to(self.device)\n","            total += labels.size(0)\n","\n","            # Forward Pass\n","            outputs = self.best_net(images)\n","\n","            # Get predictions\n","            _, preds = torch.max(outputs.data, 1)\n","\n","            # Update Corrects\n","            running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","            # Append batch predictions and labels\n","            all_targets = torch.cat(\n","                (all_targets.to(self.device), labels.to(self.device)), dim=0\n","            )\n","            all_preds = torch.cat(\n","                (all_preds.to(self.device), preds.to(self.device)), dim=0\n","            )\n","\n","        # Calculate accuracy\n","        accuracy = running_corrects / float(total)  \n","\n","        print(f\"Test accuracy: {accuracy}\")\n","\n","        return accuracy, all_targets, all_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9weatnCY-hwK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a39Ehjju-iJC"},"source":[""],"execution_count":null,"outputs":[]}]}
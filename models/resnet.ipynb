{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"05ob9gFG3UYS"},"source":["import torch\n","import torch.nn as nn\n","from torch.nn.parameter import Parameter\n","from torch.nn import functional as F\n","import math\n","import torch.utils.model_zoo as model_zoo\n","\n","\"\"\"\n","Credits to @hshustc\n","Taken from https://github.com/hshustc/CVPR19_Incremental_Learning/tree/master/cifar100-class-incremental\n","\"\"\"\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","class BasicBlockNoReLU(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlockNoReLU, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        # out = self.relu(out)\n","\n","        return out\n","\n","class CosineLayer(nn.Module):\n","    def __init__(self, in_features, out_features, eta=True):\n","        super(CosineLayer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = Parameter(torch.Tensor(out_features, in_features))\n","        if eta:\n","            self.eta = Parameter(torch.Tensor(1))\n","        else:\n","            self.register_parameter('eta', None)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        stdv = 1. / math.sqrt(self.weight.size(1))\n","        self.weight.data.uniform_(-stdv, stdv)\n","\n","        if self.eta is not None:\n","            self.eta.data.fill_(1)\n","\n","    def forward(self, input):\n","        out = F.linear(F.normalize(input, p=2, dim=1), F.normalize(self.weight, p=2, dim=1))\n","\n","        if self.eta is not None:\n","            out = self.eta * out\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=10):\n","        self.inplanes = 16\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_layer(block, 16, layers[0])\n","        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n","        self.avgpool = nn.AvgPool2d(8, stride=1)\n","        self.fc = nn.Linear(64 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.xavier_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","    \n","    def features(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","\n","        return x\n","\n","class ResNetCosine(nn.Module):\n","\n","    def __init__(self, block, blocknorelu, layers, num_classes=100):\n","        self.inplanes = 16\n","        super(ResNetCosine, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_layer(block, 16, layers[0])\n","        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n","        self.layer3norelu = self._make_layer(blocknorelu, 64, layers[2], stride=2)\n","        self.avgpool = nn.AvgPool2d(8, stride=1)\n","        # self.fc = nn.Linear(64 * block.expansion, num_classes)\n","        self.fc = CosineLayer(64 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.xavier_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, features=False):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3norelu(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","\n","        if features == False:\n","            x = self.fc(x)\n","\n","        return x\n","\n","def resnet20(pretrained=False, **kwargs):\n","    n = 3\n","    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n","    return model\n","\n","def resnet32(pretrained=False, **kwargs):\n","    n = 5\n","    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n","    return model\n","\n","def resnet32cosine(pretrained=False, **kwargs):\n","    n = 5\n","    model = ResNetCosine(BasicBlock, BasicBlockNoReLU, [n, n, n], **kwargs)\n","    return model\n","\n","def resnet56(pretrained=False, **kwargs):\n","    n = 9\n","    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n","    return model"],"execution_count":null,"outputs":[]}]}